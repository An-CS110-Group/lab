# Lab8 Exercise3

```
./transpose 1000 33 
Testing naive transpose: 0.72 milliseconds
Testing transpose with blocking: 0.697 milliseconds
```

Part 1: Changing Array Sizes
```
./transpose 100 20
Testing naive transpose: 0.009 milliseconds
Testing transpose with blocking: 0.013 milliseconds

./transpose 1000 20
Testing naive transpose: 0.628 milliseconds
Testing transpose with blocking: 0.422 milliseconds

./transpose 2000 20
Testing naive transpose: 6.9 milliseconds
Testing transpose with blocking: 3.958 milliseconds

./transpose 5000 20
Testing naive transpose: 91.415 milliseconds
Testing transpose with blocking: 17.96 milliseconds

./transpose 10000 20
Testing naive transpose: 435.669 milliseconds
Testing transpose with blocking: 84.288 milliseconds
```
```
On my desktop, transposing with blocking is faster with n >= 1000.
If the matrix is too small, CPU cache can handle all data at the same time, hence non-block version gets faster.
When the matrix grows larger than cache itself, blocking method still allows data to go into the cache for high speed (spatial locality), while naive version will face much more cahce misses.
```
Part 2: Changing Blocksize
```
./transpose 10000 50
Testing naive transpose: 433.53 milliseconds
Testing transpose with blocking: 58.529 milliseconds

./transpose 10000 100
Testing naive transpose: 462.404 milliseconds
Testing transpose with blocking: 75.757 milliseconds

./transpose 10000 500
Testing naive transpose: 446.764 milliseconds
Testing transpose with blocking: 69.669 milliseconds

./transpose 10000 1000
Testing naive transpose: 441.422 milliseconds
Testing transpose with blocking: 84.846 milliseconds

./transpose 10000 5000
Testing naive transpose: 433.352 milliseconds
Testing transpose with blocking: 405.374 milliseconds
```
```
The optimized version remains super fast until we set block size to 5000.
It turned slow due to the size of the cache.
When the cache cannot store all data in a block, cache miss would happen very often, result in a very low speed.
```